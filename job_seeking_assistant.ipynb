{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6fd447b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-24T04:37:53.972760Z",
     "iopub.status.busy": "2025-11-24T04:37:53.972011Z",
     "iopub.status.idle": "2025-11-24T04:37:56.495326Z",
     "shell.execute_reply": "2025-11-24T04:37:56.494177Z"
    },
    "papermill": {
     "duration": 2.532223,
     "end_time": "2025-11-24T04:37:56.497090",
     "exception": false,
     "start_time": "2025-11-24T04:37:53.964867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a82b99",
   "metadata": {
    "papermill": {
     "duration": 0.004449,
     "end_time": "2025-11-24T04:37:56.506458",
     "exception": false,
     "start_time": "2025-11-24T04:37:56.502009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Introduction â€” Job-Seeking Multi-Agent AI System**\n",
    "\n",
    "This notebook demonstrates the design and implementation of a multi-agent AI system for intelligent job-seeking support. Built using Googleâ€™s Agent Development Kit (ADK) and Gemini models, the system automates several key stages in the job application process, including:\n",
    "\n",
    "Analysing a job description for required skills and ATS keywordsRevising and tailoring a candidateâ€™s CV for the roleGenerating a professional cover letterResearching company context and recent newsSupporting interview preparation\n",
    "\n",
    "Rather than relying on a single monolithic agent, this system follows a multi-agent architecture, where each agent is specialized for a specific task (e.g., job analysis, CV rewriting, research, or coaching). These agents are coordinated by a root agent that ensures all steps are executed in the correct sequence.\n",
    "\n",
    "The overall objective of this notebook is to demonstrate how agentic AI can be applied to a real-world use case: improving efficiency, relevance, and personalization in the job-application workflow.\n",
    "\n",
    "This system can be extended and adapted to other career-related scenarios, such as internship matching, career advising, or recruitment analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de7af8",
   "metadata": {
    "papermill": {
     "duration": 0.004376,
     "end_time": "2025-11-24T04:37:56.515423",
     "exception": false,
     "start_time": "2025-11-24T04:37:56.511047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This block retrieves the Google API key from Kaggleâ€™s secrets manager and stores it as an environment variable. This key is required for authenticating calls to the Gemini model used by the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfc584a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:37:56.526341Z",
     "iopub.status.busy": "2025-11-24T04:37:56.525407Z",
     "iopub.status.idle": "2025-11-24T04:37:56.735492Z",
     "shell.execute_reply": "2025-11-24T04:37:56.734252Z"
    },
    "papermill": {
     "duration": 0.2174,
     "end_time": "2025-11-24T04:37:56.737231",
     "exception": false,
     "start_time": "2025-11-24T04:37:56.519831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup and authentication complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "try:\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    print(\"âœ… Setup and authentication complete.\")\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44ef75",
   "metadata": {
    "papermill": {
     "duration": 0.004625,
     "end_time": "2025-11-24T04:37:56.746669",
     "exception": false,
     "start_time": "2025-11-24T04:37:56.742044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This block imports the core components of the Google Agent Development Kit (ADK), including:\n",
    "\n",
    "Agent and specialized agent types (Sequential, Parallel, Loop)\n",
    "Gemini as the underlying LLM\n",
    "google_search as an external information tool\n",
    "InMemoryRunner for executing and testing agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4afd265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:37:56.757337Z",
     "iopub.status.busy": "2025-11-24T04:37:56.757034Z",
     "iopub.status.idle": "2025-11-24T04:38:53.003040Z",
     "shell.execute_reply": "2025-11-24T04:38:53.001821Z"
    },
    "papermill": {
     "duration": 56.25783,
     "end_time": "2025-11-24T04:38:53.009091",
     "exception": false,
     "start_time": "2025-11-24T04:37:56.751261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools import google_search, AgentTool, ToolContext\n",
    "from google.adk.code_executors import BuiltInCodeExecutor\n",
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94427c1f",
   "metadata": {
    "papermill": {
     "duration": 0.004772,
     "end_time": "2025-11-24T04:38:53.018595",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.013823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This function extracts and displays the tool-generated Python code and its results from the agentâ€™s response object. It is useful for debugging and transparency when agents use a code executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee844df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:38:53.030558Z",
     "iopub.status.busy": "2025-11-24T04:38:53.029009Z",
     "iopub.status.idle": "2025-11-24T04:38:53.037740Z",
     "shell.execute_reply": "2025-11-24T04:38:53.036562Z"
    },
    "papermill": {
     "duration": 0.016189,
     "end_time": "2025-11-24T04:38:53.039370",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.023181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "def show_python_code_and_result(response):\n",
    "    for i in range(len(response)):\n",
    "        # Check if the response contains a valid function call result from the code executor\n",
    "        if (\n",
    "            (response[i].content.parts)\n",
    "            and (response[i].content.parts[0])\n",
    "            and (response[i].content.parts[0].function_response)\n",
    "            and (response[i].content.parts[0].function_response.response)\n",
    "        ):\n",
    "            response_code = response[i].content.parts[0].function_response.response\n",
    "            if \"result\" in response_code and response_code[\"result\"] != \"```\":\n",
    "                if \"tool_code\" in response_code[\"result\"]:\n",
    "                    print(\n",
    "                        \"Generated Python Code >> \",\n",
    "                        response_code[\"result\"].replace(\"tool_code\", \"\"),\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"Generated Python Response >> \", response_code[\"result\"])\n",
    "\n",
    "\n",
    "print(\"âœ… Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8abcf",
   "metadata": {
    "papermill": {
     "duration": 0.004696,
     "end_time": "2025-11-24T04:38:53.049420",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.044724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This block defines HTTP retry rules in the event of API failures, such as:\n",
    "\n",
    "Rate limits (429)\n",
    "\n",
    "Server errors (500+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d2b3fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:38:53.060422Z",
     "iopub.status.busy": "2025-11-24T04:38:53.060107Z",
     "iopub.status.idle": "2025-11-24T04:38:53.065346Z",
     "shell.execute_reply": "2025-11-24T04:38:53.064299Z"
    },
    "papermill": {
     "duration": 0.012839,
     "end_time": "2025-11-24T04:38:53.066990",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.054151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf791a8b",
   "metadata": {
    "papermill": {
     "duration": 0.00459,
     "end_time": "2025-11-24T04:38:53.076394",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.071804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " ## **Agent Systems**\n",
    "\n",
    " * job research agent - provide similar job openings\n",
    " * job analyst agent - conduct job analysis for the job\n",
    " * CV writer agent - revised the cv with the keywords identified\n",
    " * CL writer agent - draft a cover letter based on revised cv and job description\n",
    " * Coach agent - proposed some interview questions and mock answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159ca596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:38:53.087652Z",
     "iopub.status.busy": "2025-11-24T04:38:53.087298Z",
     "iopub.status.idle": "2025-11-24T04:38:53.096942Z",
     "shell.execute_reply": "2025-11-24T04:38:53.095958Z"
    },
    "papermill": {
     "duration": 0.017273,
     "end_time": "2025-11-24T04:38:53.098339",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.081066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research_agent updated with output_key='similar_jobs'\n",
      "job_analyst_agent updated with ATS scoring\n",
      "cvwriter_agent updated.\n",
      "clwriter_agent updated.\n"
     ]
    }
   ],
   "source": [
    "#job research agent\n",
    "\n",
    "research_agent = Agent(\n",
    "    name=\"research_agent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    instruction=\"\"\"\n",
    "You are a job search agent.\n",
    "\n",
    "You MUST use the google_search tool.\n",
    "\n",
    "Based on the job description in the conversation, find 3 real job postings that are similar to this role:\n",
    "- Titles: Data & Insights Analyst, Data Analyst, CX Analyst, Customer Insights Analyst, or very similar.\n",
    "- Location: Toronto, ON OR Remote roles open to candidates in Canada.\n",
    "\n",
    "For EACH job, return:\n",
    "- Job Title\n",
    "- Company\n",
    "- Location\n",
    "- URL\n",
    "\n",
    "Output format:\n",
    "- A markdown bullet list.\n",
    "- Each bullet in the format:\n",
    "  - Job Title â€“ Company (Location) â€” URL\n",
    "\n",
    "Rules:\n",
    "- Use google_search to find current postings (do NOT invent companies).\n",
    "- Return ONLY the bullet list. No extra commentary.\n",
    "\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"similar_jobs\",\n",
    ")\n",
    "\n",
    "print(\"Research_agent updated with output_key='similar_jobs'\")\n",
    "\n",
    "\n",
    "#job analyst agent\n",
    "\n",
    "job_analyst_agent = Agent(\n",
    "    name=\"job_analyst_agent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    instruction=\"\"\"\n",
    "You are an ATS-style job analysis agent.\n",
    "\n",
    "You will receive a single message that contains BOTH:\n",
    "- A job description\n",
    "- A candidate CV\n",
    "\n",
    "Your tasks:\n",
    "1. Identify and list:\n",
    "   - Hard Skills & Technologies\n",
    "   - Soft Skills\n",
    "   - Key Qualifications & Education\n",
    "2. Extract the Top 15 ATS Keywords (comma-separated).\n",
    "3. Estimate an ATS match score (0â€“100%) for how well this CV fits the job,\n",
    "   based on keyword overlap, experience alignment, and responsibilities.\n",
    "\n",
    "Output format (markdown):\n",
    "\n",
    "### Hard Skills & Technologies\n",
    "- ...\n",
    "\n",
    "### Soft Skills\n",
    "- ...\n",
    "\n",
    "### Key Qualifications & Education\n",
    "- ...\n",
    "\n",
    "### Top 15 ATS Keywords\n",
    "keyword1, keyword2, ...\n",
    "\n",
    "### ATS Match Score\n",
    "XX%\n",
    "\n",
    "Return ONLY this analysis in markdown.\n",
    "\"\"\",\n",
    "    output_key=\"keywords\",   # <- weâ€™ll print this block, including the ATS score\n",
    ")\n",
    "\n",
    "print(\"job_analyst_agent updated with ATS scoring\")\n",
    "\n",
    "\n",
    "# CV Writer Agent\n",
    "\n",
    "cvwriter_agent = Agent(\n",
    "    name=\"cvwriter_agent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    instruction=\"\"\"\n",
    "You are an expert CV writer.\n",
    "\n",
    "You will receive ONE message that contains:\n",
    "- A job description after the line: \"========= JOB DESCRIPTION =========\"\n",
    "- A current CV after the line: \"========= CURRENT CV =========\"\n",
    "\n",
    "Your job:\n",
    "1. Read the job description and identify the key skills, responsibilities, and ATS keywords.\n",
    "2. Rewrite the CV so it is clearly tailored to this role.\n",
    "3. Reorder and rephrase experience bullets to highlight the most relevant achievements.\n",
    "4. Use metrics where possible (e.g., \"15+ campaigns\", \"20% improvement\", etc.).\n",
    "5. Keep the format clean, professional, and ATS-friendly.\n",
    "\n",
    "Very important:\n",
    "- Assume the job description and CV are already provided in the same message.\n",
    "- Do NOT ask the user to paste anything.\n",
    "- Do NOT explain what you are going to do.\n",
    "- Do NOT repeat the job description.\n",
    "- Do NOT repeat the original CV.\n",
    "\n",
    "Return ONLY the final revised CV.\n",
    "\"\"\",\n",
    "    output_key=\"revisedcv\",\n",
    ")\n",
    "print(\"cvwriter_agent updated.\")\n",
    "\n",
    "\n",
    "#Cover letter writing agent\n",
    "\n",
    "clwriter_agent = Agent(\n",
    "    name=\"clwriter_agent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    instruction=\"\"\"\n",
    "You are a professional cover letter writer.\n",
    "\n",
    "You will receive ONE message that contains:\n",
    "- A job description\n",
    "- A current CV (candidate profile)\n",
    "\n",
    "Your job:\n",
    "1. Write a tailored cover letter for this specific role and company.\n",
    "2. Use a clear business letter format with:\n",
    "   - Candidate name and contact info at the top (you can infer from the CV).\n",
    "   - Date\n",
    "   - Greeting (\"Dear Hiring Manager,\" if no name is given)\n",
    "   - 3â€“4 short paragraphs:\n",
    "     * Opening: role applied for and a 1â€“2 sentence value proposition.\n",
    "     * Middle: 1â€“2 paragraphs linking the candidateâ€™s experience to the job requirements with concrete examples.\n",
    "     * Closing: enthusiasm + call to action.\n",
    "   - Professional closing and name.\n",
    "\n",
    "Very important:\n",
    "- Base the content on the job description and CV provided in the message.\n",
    "- Do NOT ask for more information.\n",
    "- Do NOT explain what you are doing.\n",
    "- Do NOT repeat the full job description or full CV.\n",
    "\n",
    "Return ONLY the final cover letter text.\n",
    "\"\"\",\n",
    "    output_key=\"coverletter\",\n",
    ")\n",
    "print(\"clwriter_agent updated.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "577fc283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:38:53.109949Z",
     "iopub.status.busy": "2025-11-24T04:38:53.109128Z",
     "iopub.status.idle": "2025-11-24T04:38:53.115744Z",
     "shell.execute_reply": "2025-11-24T04:38:53.114702Z"
    },
    "papermill": {
     "duration": 0.014291,
     "end_time": "2025-11-24T04:38:53.117429",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.103138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coach_agent updated with output_key='interview_guide'\n"
     ]
    }
   ],
   "source": [
    "#Interview Coach Agent\n",
    "\n",
    "coach_agent = Agent(\n",
    "    name=\"coach_agent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config,\n",
    "    ),\n",
    "    instruction=\"\"\"\n",
    "You are an interview coach.\n",
    "\n",
    "You will receive a message that contains:\n",
    "- The job description\n",
    "- The candidate's CV (or revised CV)\n",
    "\n",
    "Your job is to produce an interview preparation guide with THREE sections, all tailored to THIS role and THIS candidate:\n",
    "\n",
    "## Behavioural / Fit Questions\n",
    "- 5â€“7 behavioural or culture-fit questions.\n",
    "- For each question, provide a strong sample answer in the first person (\"I ...\") that fits the candidateâ€™s profile.\n",
    "\n",
    "## Technical / Analytics Questions\n",
    "- 5â€“7 technical / analytics questions related to:\n",
    "  - SQL / querying data\n",
    "  - Dashboards (Power BI)\n",
    "  - Customer Experience metrics (NPS, CSAT, CES)\n",
    "  - A/B testing and experiment design\n",
    "  - Survey design and analysis\n",
    "- For each question, provide a strong sample answer tailored to the candidate.\n",
    "\n",
    "## Questions to Ask the Employer\n",
    "- 5 thoughtful questions the candidate can ask the interviewer about:\n",
    "  - The role\n",
    "  - The data / tools\n",
    "  - The team and stakeholders\n",
    "  - Expectations and success metrics\n",
    "\n",
    "Important rules:\n",
    "- Base everything on THIS specific job and candidate.\n",
    "- Do NOT ask the user for more information.\n",
    "- Do NOT explain what you are doing.\n",
    "- Do NOT repeat the full job description or CV.\n",
    "\n",
    "Return ONLY the interview preparation guide in markdown.\n",
    "\"\"\",\n",
    "    output_key=\"interview_guide\",\n",
    ")\n",
    "\n",
    "print(\"Coach_agent updated with output_key='interview_guide'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0318392",
   "metadata": {
    "papermill": {
     "duration": 0.00481,
     "end_time": "2025-11-24T04:38:53.127084",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.122274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Core inputs for the system**\n",
    "\n",
    "* The job ad defines the target requirements\n",
    "* The CV is the raw material for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2852702b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:38:53.138721Z",
     "iopub.status.busy": "2025-11-24T04:38:53.138383Z",
     "iopub.status.idle": "2025-11-24T04:38:53.145078Z",
     "shell.execute_reply": "2025-11-24T04:38:53.144062Z"
    },
    "papermill": {
     "duration": 0.014828,
     "end_time": "2025-11-24T04:38:53.146729",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.131901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_ad_text = \"\"\"Job Title: Data & Insights Analyst â€“ Customer Experience\n",
    "\n",
    "Company: Nova Retail Solutions Inc.\n",
    "Location: Toronto, ON (Hybrid â€“ 3 days in office)\n",
    "Salary Range: $70,000 â€“ $90,000 per year\n",
    "\n",
    "About the Company\n",
    "Nova Retail Solutions is a fast-growing omni-channel retail analytics company that helps national brands understand customer behaviour across online and in-store environments. We use data, AI, and customer research to optimize experiences and increase lifetime value.\n",
    "\n",
    "About the Role\n",
    "\n",
    "We are seeking a Data & Insights Analyst â€“ Customer Experience to join our Customer Intelligence team. In this role, you will support the analysis, reporting, and interpretation of customer experience (CX) data and deliver actionable insights to internal stakeholders.\n",
    "\n",
    "This is an ideal opportunity for a detail-oriented analyst who enjoys working with data, generating stories, and influencing business decisions.\n",
    "\n",
    "Key Responsibilities\n",
    "\n",
    "â€¢ Analyze customer data from multiple sources (survey results, CRM, web analytics, loyalty programs)\n",
    "â€¢ Design and manage customer surveys to measure sentiment, satisfaction, and NPS\n",
    "â€¢ Build weekly and monthly dashboards using Power BI\n",
    "â€¢ Conduct quantitative and qualitative analysis on customer feedback\n",
    "â€¢ Identify patterns, trends, and opportunities to improve customer journeys\n",
    "â€¢ Present findings and recommendations to marketing, product, and leadership teams\n",
    "â€¢ Support A/B testing initiatives and campaign measurement\n",
    "\n",
    "Required Qualifications\n",
    "\n",
    "â€¢ Bachelorâ€™s degree in Business Analytics, Marketing, Statistics, or related field\n",
    "â€¢ 2+ years of experience in data analysis or market research\n",
    "â€¢ Strong proficiency in Excel (advanced formulas, pivot tables, VLOOKUP)\n",
    "â€¢ Experience with Power BI or Tableau\n",
    "â€¢ Basic knowledge of SQL for data querying\n",
    "â€¢ Understanding of customer experience metrics (NPS, CSAT, CES)\n",
    "â€¢ Strong written and verbal communication skills\n",
    "\n",
    "Preferred Qualifications\n",
    "\n",
    "â€¢ Experience in retail, e-commerce, or consumer goods industries\n",
    "â€¢ Familiarity with Python or R for analysis\n",
    "â€¢ Knowledge of survey platforms (Qualtrics, SurveyMonkey)\n",
    "â€¢ Experience working with CRM datasets\n",
    "\n",
    "Key Skills\n",
    "\n",
    "Data Analysis, Customer Experience (CX), Power BI, Excel, SQL, Survey Design, A/B Testing, Reporting, Stakeholder Communication, Data Visualization, Machine Learning (basic), Marketing Analytics\n",
    "\n",
    "Why Join Us?\n",
    "\n",
    "â€¢ Work with a collaborative and innovative team\n",
    "â€¢ Opportunity for professional growth and learning\n",
    "â€¢ Competitive salary and benefits\n",
    "â€¢ Hybrid work environment\n",
    "â€¢ High-impact projects supporting top retail brands\n",
    "\n",
    "How to Apply:\n",
    "Submit your resume and cover letter to careers@novaretail.ai\n",
    "\"\"\"\n",
    "\n",
    "base_cv_text = \"\"\"Name: Alex Thompson\n",
    "Location: Toronto, ON\n",
    "Email: alex.thompson@email.com\n",
    "Phone: 647-555-0198\n",
    "LinkedIn: linkedin.com/in/alexthompson\n",
    "\n",
    "Professional Summary\n",
    "\n",
    "Aspiring data analyst with strong analytical skills and a background in business and marketing. Experienced in handling survey data, building dashboards, and supporting decision-making with data-driven insights. Seeking a growth opportunity in customer experience analytics.\n",
    "\n",
    "Education\n",
    "\n",
    "Bachelor of Commerce (Marketing & Analytics)\n",
    "University of Toronto, 2021\n",
    "\n",
    "Technical Skills\n",
    "\n",
    "â€¢ Microsoft Excel (advanced)\n",
    "â€¢ Power BI (intermediate)\n",
    "â€¢ SQL (basic)\n",
    "â€¢ Python (beginner)\n",
    "â€¢ SPSS\n",
    "â€¢ Google Analytics\n",
    "â€¢ SurveyMonkey, Qualtrics\n",
    "\n",
    "Work Experience\n",
    "\n",
    "Marketing Data Assistant\n",
    "BrightPath Marketing Agency\n",
    "Jan 2023 â€“ Present\n",
    "\n",
    "â€¢ Supported data analysis for 15+ client campaigns\n",
    "â€¢ Built Power BI dashboards to track customer engagement\n",
    "â€¢ Cleaned and organized survey and CRM data\n",
    "â€¢ Prepared weekly reports for account managers\n",
    "â€¢ Helped conduct A/B testing on email campaigns\n",
    "\n",
    "Customer Service Associate\n",
    "Urban Essentials Retail\n",
    "Jun 2021 â€“ Dec 2022\n",
    "\n",
    "â€¢ Assisted 50+ customers daily and resolved inquiries\n",
    "â€¢ Collected customer feedback and suggestions\n",
    "â€¢ Maintained high customer satisfaction ratings\n",
    "â€¢ Identified recurring issues and reported to management\n",
    "\n",
    "Academic Project â€“ Customer Satisfaction Study\n",
    "\n",
    "â€¢ Designed and distributed survey to 250 participants\n",
    "â€¢ Analyzed responses using SPSS and Excel\n",
    "â€¢ Presented insights on factors affecting satisfaction\n",
    "\n",
    "Certifications\n",
    "\n",
    "â€¢ Google Data Analytics Certificate (Coursera)\n",
    "â€¢ Power BI Fundamentals (Microsoft Learn)\n",
    "\n",
    "Soft Skills\n",
    "\n",
    "Analytical Thinking\n",
    "Communication\n",
    "Attention to Detail\n",
    "Problem Solving\n",
    "Teamwork\n",
    "Customer Focus\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f15517a",
   "metadata": {
    "papermill": {
     "duration": 0.004801,
     "end_time": "2025-11-24T04:38:53.156597",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.151796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Individual Agent Execution Pipeline**\n",
    "\n",
    "**This function allows the system to:**\n",
    "\n",
    "* Run each agent independently\n",
    "* Extract its output from the state\n",
    "* Store results in separate variables\n",
    "\n",
    "\n",
    "**Execution Order**\n",
    "\n",
    "* ATS & keyword analysis\n",
    "* CV revision\n",
    "* Cover letter generation\n",
    "* Interview guide\n",
    "* Similar job discovery\n",
    "\n",
    "Each is handled by its specialised agent, showing clean modular design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d28d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:38:53.167920Z",
     "iopub.status.busy": "2025-11-24T04:38:53.167451Z",
     "iopub.status.idle": "2025-11-24T04:39:11.459594Z",
     "shell.execute_reply": "2025-11-24T04:39:11.458545Z"
    },
    "papermill": {
     "duration": 18.300077,
     "end_time": "2025-11-24T04:39:11.461354",
     "exception": false,
     "start_time": "2025-11-24T04:38:53.161277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ATS / KEYWORDS =====\n",
      "\n",
      "### Hard Skills & Technologies\n",
      "- Microsoft Excel (advanced formulas, pivot tables, VLOOKUP)\n",
      "- Power BI\n",
      "- SQL (basic)\n",
      "- Python (beginner)\n",
      "- Google Analytics\n",
      "- SurveyMonkey\n",
      "- Qualtrics\n",
      "- SPSS\n",
      "- A/B Testing\n",
      "- Data Analysis\n",
      "- Reporting\n",
      "- Data Visualization\n",
      "\n",
      "### Soft Skills\n",
      "- Analytical Thinking\n",
      "- Communication (written and verbal)\n",
      "- Attention to Detail\n",
      "- Problem Solving\n",
      "- Teamwork\n",
      "- Customer Focus\n",
      "- Stakeholder Communication (implied through reporting to account managers and presenting insights)\n",
      "\n",
      "### Key Qualifications & Education\n",
      "- Bachelor of Commerce (Marketing & Analytics)\n",
      "- 2+ years of experience in data analysis or market research (Jan 2023 - Present as Marketing Data Assistant + Academic Project)\n",
      "- Understanding of customer experience metrics (implied through survey analysis, customer feedback collection)\n",
      "\n",
      "### Top 15 ATS Keywords\n",
      "Data Analysis, Customer Experience, CX, Power BI, Excel, SQL, Survey Design, A/B Testing, Reporting, Data Visualization, Marketing Analytics, Customer Feedback, CRM, Customer Satisfaction, NPS\n",
      "\n",
      "### ATS Match Score\n",
      "89%\n",
      "\n",
      "===== REVISED CV =====\n",
      "\n",
      "Alex Thompson\n",
      "Toronto, ON | 647-555-0198 | alex.thompson@email.com | linkedin.com/in/alexthompson\n",
      "\n",
      "Summary\n",
      "\n",
      "Detail-oriented Data & Insights Analyst with 2+ years of experience in analyzing customer data, designing surveys, and developing impactful reports and dashboards. Proven ability to translate complex datasets into actionable insights that drive improvements in customer experience and business strategy. Proficient in Excel, Power BI, and SQL, with a strong understanding of key CX metrics (NPS, CSAT). Eager to leverage analytical skills to enhance customer journeys at Nova Retail Solutions.\n",
      "\n",
      "Experience\n",
      "\n",
      "Marketing Data Assistant | BrightPath Marketing Agency | Jan 2023 â€“ Present\n",
      "\n",
      "*   Analyzed customer data from diverse sources, including survey results, CRM, and web analytics, to support over 15 client marketing campaigns.\n",
      "*   Designed, built, and maintained weekly and monthly dashboards in Power BI, visualizing key customer engagement metrics and campaign performance for internal stakeholders.\n",
      "*   Managed and cleaned large datasets from survey responses and CRM systems, ensuring data integrity for accurate analysis.\n",
      "*   Conducted quantitative analysis of customer feedback and survey data to identify trends and patterns, contributing to campaign optimization.\n",
      "*   Supported A/B testing initiatives for digital marketing campaigns, analyzing results to measure effectiveness and recommend improvements.\n",
      "*   Generated comprehensive weekly reports for account managers, highlighting campaign performance and customer insights.\n",
      "\n",
      "Customer Service Associate | Urban Essentials Retail | Jun 2021 â€“ Dec 2022\n",
      "\n",
      "*   Provided direct assistance to an average of 50+ customers daily, consistently achieving high customer satisfaction ratings through effective problem resolution.\n",
      "*   Proactively collected and documented customer feedback and suggestions, identifying recurring issues and reporting key trends to management.\n",
      "*   Utilized insights from customer interactions to recommend process improvements, contributing to a better in-store experience.\n",
      "\n",
      "Education\n",
      "\n",
      "Bachelor of Commerce (Marketing & Analytics)\n",
      "University of Toronto | 2021\n",
      "\n",
      "Technical Skills\n",
      "\n",
      "*   **Data Analysis & Visualization:** Power BI (intermediate), Google Analytics, SPSS\n",
      "*   **Data Management:** Advanced Excel (Pivot Tables, VLOOKUP, Formulas), Basic SQL\n",
      "*   **Survey & CX:** SurveyMonkey, Qualtrics, NPS, CSAT, CES\n",
      "*   **Programming:** Python (beginner)\n",
      "*   **Other:** A/B Testing, Reporting, CRM Data\n",
      "\n",
      "Certifications\n",
      "\n",
      "*   Google Data Analytics Certificate (Coursera)\n",
      "*   Power BI Fundamentals (Microsoft Learn)\n",
      "\n",
      "===== COVER LETTER =====\n",
      "\n",
      "Alex Thompson\n",
      "647-555-0198\n",
      "alex.thompson@email.com\n",
      "Toronto, ON\n",
      "\n",
      "[Date]\n",
      "\n",
      "Hiring Manager\n",
      "Nova Retail Solutions Inc.\n",
      "careers@novaretail.ai\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my enthusiastic interest in the Data & Insights Analyst â€“ Customer Experience position at Nova Retail Solutions Inc., as advertised. With my background in marketing analytics, hands-on experience with data analysis tools, and a passion for understanding customer behaviour, I am confident I can deliver valuable insights to your team and contribute to Nova Retail's mission of optimizing customer experiences.\n",
      "\n",
      "In my current role as a Marketing Data Assistant at BrightPath Marketing Agency, I have honed my abilities in analyzing data from various sources and translating it into actionable reports. I regularly build Power BI dashboards to track customer engagement and have experience cleaning and organizing survey and CRM data, mirroring the key responsibilities outlined in your job description. My academic project further demonstrates my capability in survey design and analysis, where I successfully designed, distributed, and analyzed a customer satisfaction study.\n",
      "\n",
      "I possess strong proficiency in Excel, including advanced formulas and pivot tables, and have intermediate experience with Power BI. My basic SQL knowledge allows me to query data effectively, and I am familiar with customer experience metrics such as NPS and CSAT. I am eager to leverage these skills, along with my understanding of A/B testing and reporting, to identify patterns and trends that will improve customer journeys for Nova Retail's clients.\n",
      "\n",
      "I am particularly drawn to Nova Retail Solutions' focus on omni-channel retail analytics and the opportunity to work with a collaborative and innovative team. My background in customer service has instilled in me a deep customer focus, which I believe is essential for this role. I am excited by the prospect of contributing to high-impact projects and growing my career within your dynamic company.\n",
      "\n",
      "Thank you for considering my application. I have attached my resume for your review and welcome the opportunity to discuss how my skills and experience align with the needs of Nova Retail Solutions Inc.\n",
      "\n",
      "Sincerely,\n",
      "Alex Thompson\n",
      "\n",
      "===== INTERVIEW PREP (COACH AGENT) =====\n",
      "\n",
      "## Behavioural / Fit Questions\n",
      "\n",
      "*   **Question:** Tell me about a time you had to analyze customer feedback from multiple sources and synthesize it into a clear recommendation. How did you approach it?\n",
      "    *   **Sample Answer:** In my previous role as a Marketing Data Assistant at BrightPath Marketing Agency, I often dealt with fragmented customer feedback from various client campaigns. For one campaign, we had survey responses, website engagement data, and direct customer comments. My approach was to first consolidate all the data into a usable format, cleaning and organizing it in Excel. Then, I used Excel's pivot tables and basic statistical functions to identify recurring themes and patterns in the qualitative feedback, cross-referencing these with quantitative metrics from the surveys and website analytics. I then presented these synthesized insights to the account managers, highlighting key areas for improvement in the customer journey, which ultimately led to a revised campaign strategy that improved engagement.\n",
      "\n",
      "*   **Question:** This role involves presenting findings to different stakeholders, including marketing, product, and leadership teams. Can you describe your experience in communicating complex data insights to non-technical audiences?\n",
      "    *   **Sample Answer:** I've had significant experience presenting data insights to diverse audiences. At BrightPath, I regularly prepared weekly reports for account managers, who had varying levels of data literacy. I focused on translating the raw numbers into a clear narrative, using visualizations in Power BI to illustrate key trends and their business implications. For instance, when presenting A/B test results for email campaigns, I wouldn't just show click-through rates; I'd explain what those rates meant for customer engagement and what actions we should take. I always tailor my language and level of detail to the audience, ensuring the insights are actionable and easy to understand.\n",
      "\n",
      "*   **Question:** Describe a situation where you identified a trend or pattern in data that led to an opportunity for improvement.\n",
      "    *   **Sample Answer:** During my academic project on customer satisfaction, I designed and distributed a survey to 250 participants. While analyzing the responses using SPSS and Excel, I noticed a pattern: customers who reported longer wait times for support also reported significantly lower satisfaction scores, even if their primary issue was resolved. This was a clear opportunity to improve a critical part of the customer journey. I presented this finding, recommending a review of support staffing and response protocols. The insights were well-received and contributed to a broader discussion about optimizing customer service efficiency.\n",
      "\n",
      "*   **Question:** This role requires working collaboratively with a team. Can you share an example of a time you worked effectively within a team to achieve a common goal?\n",
      "    *   **Sample Answer:** As a Marketing Data Assistant, I often collaborated with account managers and campaign specialists. For a major client launch, our team needed to provide real-time performance tracking. I worked closely with the campaign manager to understand their key performance indicators and then built a series of Power BI dashboards that provided daily updates on customer engagement and conversion rates. We had regular check-ins to ensure the data was being interpreted correctly and that any emerging trends were addressed promptly. This collaborative effort ensured the client had the visibility they needed to optimize their campaign on the fly.\n",
      "\n",
      "*   **Question:** How do you ensure accuracy and attention to detail when working with large datasets and building reports?\n",
      "    *   **Sample Answer:** Accuracy and attention to detail are paramount in data analysis. My process involves several checks. When cleaning data, I use Excel's data validation and conditional formatting to spot anomalies. When building dashboards in Power BI, I cross-reference the metrics with source data and perform sanity checks on aggregations and calculations. I also make it a habit to double-check my work before presenting it, and if possible, I have a colleague review critical reports or dashboards to catch any errors I might have missed. My experience with SPSS and advanced Excel functions has also honed my ability to scrutinize data meticulously.\n",
      "\n",
      "*   **Question:** What motivates you to work in customer experience analytics specifically?\n",
      "    *   **Sample Answer:** I'm motivated by the direct impact customer experience analytics has on business success. I find it incredibly rewarding to take raw customer data, understand the 'why' behind customer behavior, and translate that into actionable insights that can genuinely improve a customer's journey and, in turn, drive business growth. My background in marketing and my customer service experience have given me a deep appreciation for the customer perspective, and I'm excited by the opportunity to use data to advocate for and enhance that experience at Nova Retail Solutions.\n",
      "\n",
      "## Technical / Analytics Questions\n",
      "\n",
      "*   **Question:** Imagine you have two tables: `customers` (with columns `customer_id`, `name`, `signup_date`) and `orders` (with columns `order_id`, `customer_id`, `order_date`, `order_total`). Write a SQL query to find the total order value for each customer who signed up in the last 30 days.\n",
      "    *   **Sample Answer:**\n",
      "        ```sql\n",
      "        SELECT\n",
      "            c.customer_id,\n",
      "            c.name,\n",
      "            SUM(o.order_total) AS total_order_value\n",
      "        FROM\n",
      "            customers c\n",
      "        JOIN\n",
      "            orders o ON c.customer_id = o.customer_id\n",
      "        WHERE\n",
      "            c.signup_date >= DATE('now', '-30 days') -- Assuming SQLite syntax, adjust for specific SQL dialect\n",
      "        GROUP BY\n",
      "            c.customer_id, c.name\n",
      "        ORDER BY\n",
      "            total_order_value DESC;\n",
      "        ```\n",
      "        *(Self-correction: I'd ensure the `DATE()` function syntax is correct for the specific SQL database Nova Retail Solutions uses, e.g., `GETDATE() - 30` for SQL Server or `CURRENT_DATE - INTERVAL '30 day'` for PostgreSQL).*\n",
      "\n",
      "*   **Question:** You need to build a Power BI dashboard to track customer satisfaction over time. What key metrics would you include, and how would you visualize them?\n",
      "    *   **Sample Answer:** For a customer satisfaction dashboard in Power BI, I would include:\n",
      "        *   **Overall CSAT Score:** A KPI card showing the current average CSAT score.\n",
      "        *   **NPS Trend:** A line chart showing Net Promoter Score over time (weekly/monthly) to track sentiment shifts.\n",
      "        *   **CES Trend:** A line chart for Customer Effort Score over time, indicating ease of interaction.\n",
      "        *   **Distribution of Scores:** A bar chart showing the percentage breakdown of responses for each satisfaction level (e.g., Very Dissatisfied to Very Satisfied) for CSAT questions.\n",
      "        *   **Key Driver Analysis:** Possibly a bar chart or scatter plot correlating specific touchpoints (e.g., support interaction, website navigation) with satisfaction scores to identify drivers.\n",
      "        *   **Filters:** Slicers for date range, customer segment, and product/service type to allow for deeper dives.\n",
      "        I would use clear titles, consistent color schemes, and tooltips to provide additional context on hover.\n",
      "\n",
      "*   **Question:** Explain the difference between NPS, CSAT, and CES, and when you might use each.\n",
      "    *   **Sample Answer:**\n",
      "        *   **NPS (Net Promoter Score):** Measures overall customer loyalty and willingness to recommend. It asks, \"On a scale of 0-10, how likely are you to recommend [company/product] to a friend or colleague?\" It categorizes respondents into Promoters (9-10), Passives (7-8), and Detractors (0-6). I'd use NPS to gauge overall brand health and loyalty trends.\n",
      "        *   **CSAT (Customer Satisfaction):** Measures satisfaction with a specific interaction or product/service. It typically asks, \"How satisfied were you with [interaction/product]?\" on a scale (e.g., 1-5). I'd use CSAT immediately after a customer touchpoint (like a support call or purchase) to measure the success of that specific interaction.\n",
      "        *   **CES (Customer Effort Score):** Measures how much effort a customer had to exert to get an issue resolved or a request fulfilled. It asks, \"How easy was it to handle your request?\" on a scale (e.g., Very Difficult to Very Easy). I'd use CES to identify friction points in the customer journey, particularly in support or service processes, as reducing effort often correlates with loyalty.\n",
      "\n",
      "*   **Question:** You're asked to design an A/B test for a new checkout button color on an e-commerce website. What steps would you take from hypothesis generation to analysis?\n",
      "    *   **Sample Answer:**\n",
      "        1.  **Hypothesis:** \"Changing the checkout button color from blue (current) to green will increase the conversion rate because green is often associated with 'go' or 'success' and might stand out more effectively.\"\n",
      "        2.  **Define Metrics:** Primary metric: Checkout completion rate (conversion rate). Secondary metrics: Add-to-cart rate, bounce rate on the checkout page.\n",
      "        3.  **Experiment Design:** Use an A/B testing tool (like Google Optimize, Optimizely). Randomly assign 50% of website visitors to see the blue button (Control - A) and 50% to see the green button (Variant - B). Ensure consistent traffic allocation and run the test for a statistically significant period (e.g., 1-2 weeks, depending on traffic volume) to account for weekly variations.\n",
      "        4.  **Data Collection:** Ensure the A/B testing tool is properly integrated to track user behavior and conversions for both variants.\n",
      "        5.  **Analysis:** Once the test concludes, analyze the results using the tool's built-in statistical significance calculations. Compare the conversion rates of Group A and Group B. If the difference is statistically significant (e.g., p-value < 0.05), and the green button variant shows a higher conversion rate, we can conclude the hypothesis is supported. I would then present these findings, including confidence intervals and potential business impact.\n",
      "\n",
      "*   **Question:** How would you approach analyzing qualitative feedback from open-ended survey questions, like \"What could we do to improve your experience?\"\n",
      "    *   **Sample Answer:** My approach would involve a combination of techniques. First, I'd read through a sample of responses to get a general feel for the themes. Then, I would categorize the feedback into recurring themes or topics (e.g., \"product quality,\" \"customer service response time,\" \"website usability,\" \"pricing\"). I'd use Excel or a tool like NVivo (if available) to tag and count the frequency of each theme. I would also look for sentiment associated with each theme. Finally, I'd quantify the most common issues and provide illustrative quotes to bring the qualitative data to life for stakeholders, prioritizing based on frequency and potential impact. My experience with SPSS can also be helpful for more advanced thematic analysis if needed.\n",
      "\n",
      "*   **Question:** You've built a Power BI dashboard showing declining NPS. What further analysis would you perform to understand the root causes?\n",
      "    *   **Sample Answer:** If NPS is declining, I wouldn't stop at the overall trend. I'd immediately pivot to segmentation and drill-down analysis within Power BI.\n",
      "        1.  **Segment Analysis:** Break down NPS by customer segments (e.g., new vs. loyal customers, different demographics, product users) to see if the decline is concentrated in a specific group.\n",
      "        2.  **Correlate with Other Metrics:** Overlay NPS trends with CSAT scores for specific touchpoints (e.g., post-support interaction, post-purchase) or CES scores. Are specific interactions driving dissatisfaction?\n",
      "        3.  **Analyze Qualitative Feedback:** Dive deep into the open-ended comments from detractors during the period of decline. What specific issues are they raising?\n",
      "        4.  **Operational Data:** Look at operational metrics during that period. Did we experience increased support wait times? Website outages? Product quality issues?\n",
      "        5.  **Campaign/Product Launches:** Were there any recent product updates, marketing campaigns, or policy changes that coincided with the NPS drop?\n",
      "        By combining these quantitative and qualitative approaches, I can build a more comprehensive picture of the root causes driving the NPS decline.\n",
      "\n",
      "*   **Question:** Describe your experience with data cleaning and preparation. Why is it important?\n",
      "    *   **Sample Answer:** Data cleaning and preparation are foundational to reliable analysis. My experience involves handling inconsistencies like typos, duplicate entries, missing values, and incorrect data types. For example, in my Marketing Data Assistant role, I frequently cleaned survey and CRM data to ensure accuracy. I use tools like advanced Excel functions (VLOOKUP, TRIM, cleaning text data) and SQL queries to standardize formats and remove errors. It's crucial because \"garbage in, garbage out\" â€“ any analysis or insights derived from dirty data will be flawed and can lead to incorrect business decisions. Investing time in cleaning ensures the integrity and trustworthiness of the final outputs.\n",
      "\n",
      "## Questions to Ask the Employer\n",
      "\n",
      "1.  What are the biggest challenges the Customer Intelligence team is currently facing in leveraging customer experience data?\n",
      "2.  Can you describe the typical data sources and tools the team uses daily beyond Power BI and SQL? Are there opportunities to work with other technologies like Python or R?\n",
      "3.  What does success look like for this role in the first 3-6 months, and what are the key performance indicators I would be measured against?\n",
      "4.  Could you elaborate on the types of stakeholders I would be working with most closely, and how is customer feedback typically incorporated into product and marketing strategies?\n",
      "5.  What opportunities are there for professional development and learning within Nova Retail Solutions, particularly in the areas of data analytics and customer experience?\n",
      "\n",
      "===== SIMILAR JOBS (GOOGLE SEARCH) =====\n",
      "\n",
      "- Data & Insights Analyst â€“ Customer Experience â€“ Nova Retail Solutions Inc. (Toronto, ON) â€” https://novaretail.ai/careers/ (Note: Direct URL to specific posting not available, general careers page provided)\n",
      "- Customer Experience Analyst â€“ Integrity Staffing Solution (Toronto, ON) â€” https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFPAcUpqMq3J5IL-auNIeLfi8TavXddeDcb9vcVAl8iGD8UI9O6ugf9aZ_MzKDyIT6ZAV1cHwbhActTfS4fnMljVs9jDolovXg41PN7yrWgeGby8PNKOWG0lqpyNy_S6BzyRFgfJaJI2cvUciBETgBhArENQCWXsBMONihC-A==\n",
      "- Product & Customer Insights Analyst (Hybrid) â€“ GreenShield (Toronto, ON) â€” https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHYJpNnkhtzXiikSJIbcXTTcUjG0NYUKn5yoL6x1c98CH8Xq3CVuD0LtO_Qayz8MHP7fY9h246OCPSKQ-jpEFzbiRsXrYr_LG-d03KNd5Jar_JLU0e9sQ7hB6s_Q-VzwlY1z3Kq6_W4w==\n"
     ]
    }
   ],
   "source": [
    "from google.adk.runners import InMemoryRunner\n",
    "\n",
    "# Shared context: job ad + CV\n",
    "context_prompt = f\"\"\"\n",
    "========= JOB DESCRIPTION =========\n",
    "{job_ad_text}\n",
    "\n",
    "========= CURRENT CV =========\n",
    "{base_cv_text}\n",
    "\"\"\"\n",
    "\n",
    "def extract_state_from_events(events):\n",
    "    final_state = {}\n",
    "    if not isinstance(events, (list, tuple)):\n",
    "        events = [events]\n",
    "    for e in events:\n",
    "        actions = getattr(e, \"actions\", None)\n",
    "        if actions and getattr(actions, \"state_delta\", None):\n",
    "            final_state.update(actions.state_delta)\n",
    "    return final_state\n",
    "\n",
    "# Helper to run a single agent and get its state\n",
    "async def run_agent(agent, prompt):\n",
    "    runner = InMemoryRunner(agent=agent)\n",
    "    # quiet=True stops printing \"User > ...\" and agent traces\n",
    "    events = await runner.run_debug(prompt, quiet=True, verbose=False)\n",
    "    return extract_state_from_events(events)\n",
    "\n",
    "\n",
    "# 1) ATS + keywords (job_analyst_agent)\n",
    "keywords_state = await run_agent(job_analyst_agent, context_prompt)\n",
    "keywords_text = keywords_state.get(\"keywords\", \"No keywords / ATS analysis found.\")\n",
    "\n",
    "# 2) Revised CV (cvwriter_agent)\n",
    "cv_prompt = f\"\"\"\n",
    "You will receive a job description and a current CV.\n",
    "\n",
    "Your task:\n",
    "- Rewrite the CV so it is clearly tailored to this role.\n",
    "- Use the job description to emphasise relevant skills and experience.\n",
    "- Use metrics where possible.\n",
    "- Keep the format clean and ATS-friendly.\n",
    "\n",
    "Return ONLY the revised CV.\n",
    "\n",
    "{context_prompt}\n",
    "\"\"\"\n",
    "cv_state = await run_agent(cvwriter_agent, cv_prompt)\n",
    "revised_cv_text = cv_state.get(\"revisedcv\", \"No revised CV found.\")\n",
    "\n",
    "# 3) Cover letter (clwriter_agent)\n",
    "cl_prompt = f\"\"\"\n",
    "You will receive a job description and a current CV.\n",
    "\n",
    "Your task:\n",
    "- Write a professional cover letter for this specific role and candidate.\n",
    "- Use a clear business letter format.\n",
    "- Base the content on the job description and the candidate's profile.\n",
    "\n",
    "Return ONLY the final cover letter.\n",
    "\n",
    "{context_prompt}\n",
    "\"\"\"\n",
    "cl_state = await run_agent(clwriter_agent, cl_prompt)\n",
    "cover_letter_text = cl_state.get(\"coverletter\", \"No cover letter found.\")\n",
    "\n",
    "# 4) Interview prep (coach_agent)\n",
    "coach_prompt = f\"\"\"\n",
    "You will receive a job description and a current CV.\n",
    "\n",
    "Your task:\n",
    "- Generate an interview preparation guide for this role and candidate:\n",
    "  - 5â€“7 Behavioural / Fit questions + sample answers\n",
    "  - 5â€“7 Technical / Analytics questions + sample answers\n",
    "  - 5 smart questions the candidate should ask the employer\n",
    "\n",
    "Return ONLY the interview preparation guide in markdown.\n",
    "\n",
    "{context_prompt}\n",
    "\"\"\"\n",
    "coach_state = await run_agent(coach_agent, coach_prompt)\n",
    "interview_guide_text = coach_state.get(\"interview_guide\", \"No interview guide found.\")\n",
    "\n",
    "# 5) Similar jobs (research_agent) â€“ job ad is enough\n",
    "jobs_prompt = f\"\"\"\n",
    "Here is a job description for a Data & Insights Analyst â€“ Customer Experience role:\n",
    "\n",
    "{job_ad_text}\n",
    "\n",
    "Use google_search to find 3 similar jobs:\n",
    "- Similar title (Data & Insights Analyst, CX Analyst, Customer Insights Analyst, etc.)\n",
    "- Located in Toronto, ON or Remote (Canada)\n",
    "Return ONLY a markdown bullet list:\n",
    "- Job Title â€“ Company (Location) â€” URL\n",
    "\"\"\"\n",
    "jobs_state = await run_agent(research_agent, jobs_prompt)\n",
    "similar_jobs_text = jobs_state.get(\"similar_jobs\", \"No similar jobs found.\")\n",
    "\n",
    "# ---------- Print everything nicely ----------\n",
    "\n",
    "print(\"\\n===== ATS / KEYWORDS =====\\n\")\n",
    "print(keywords_text)\n",
    "\n",
    "print(\"\\n===== REVISED CV =====\\n\")\n",
    "print(revised_cv_text)\n",
    "\n",
    "print(\"\\n===== COVER LETTER =====\\n\")\n",
    "print(cover_letter_text)\n",
    "\n",
    "print(\"\\n===== INTERVIEW PREP (COACH AGENT) =====\\n\")\n",
    "print(interview_guide_text)\n",
    "\n",
    "print(\"\\n===== SIMILAR JOBS (GOOGLE SEARCH) =====\\n\")\n",
    "print(similar_jobs_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45cb45b",
   "metadata": {
    "papermill": {
     "duration": 0.005978,
     "end_time": "2025-11-24T04:39:11.473921",
     "exception": false,
     "start_time": "2025-11-24T04:39:11.467943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Interactive Assistant Mode**\n",
    "\n",
    "**Purpose**\n",
    "\n",
    "The final section converts the notebook into an interactive AI assistant, enabling the user to:\n",
    "\n",
    "* Paste any job ad\n",
    "* Paste any CV\n",
    "\n",
    "Choose desired tasks:\n",
    "* CV\n",
    "* Cover letter\n",
    "* Interview guide\n",
    "* Similar jobs\n",
    "* All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf06c84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:39:11.486750Z",
     "iopub.status.busy": "2025-11-24T04:39:11.485855Z",
     "iopub.status.idle": "2025-11-24T04:39:11.492282Z",
     "shell.execute_reply": "2025-11-24T04:39:11.491405Z"
    },
    "papermill": {
     "duration": 0.014468,
     "end_time": "2025-11-24T04:39:11.493784",
     "exception": false,
     "start_time": "2025-11-24T04:39:11.479316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_state_from_events(events):\n",
    "    final_state = {}\n",
    "    if not isinstance(events, (list, tuple)):\n",
    "        events = [events]\n",
    "    for e in events:\n",
    "        actions = getattr(e, \"actions\", None)\n",
    "        if actions and getattr(actions, \"state_delta\", None):\n",
    "            final_state.update(actions.state_delta)\n",
    "    return final_state\n",
    "\n",
    "async def run_agent(agent, prompt):\n",
    "    runner = InMemoryRunner(agent=agent)\n",
    "    events = await runner.run_debug(prompt, quiet=True, verbose=False)\n",
    "    return extract_state_from_events(events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3913c6ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:39:11.506830Z",
     "iopub.status.busy": "2025-11-24T04:39:11.505975Z",
     "iopub.status.idle": "2025-11-24T04:39:11.613809Z",
     "shell.execute_reply": "2025-11-24T04:39:11.612585Z"
    },
    "papermill": {
     "duration": 0.115978,
     "end_time": "2025-11-24T04:39:11.615230",
     "exception": true,
     "start_time": "2025-11-24T04:39:11.499252",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Job Application Assistant\n",
      "I'll help you with ATS analysis, CV tailoring, cover letter, interview prep, and similar jobs.\n",
      "\n",
      "\n",
      "Paste your JOB AD below. Type a single line 'END' when you are done:\n",
      "\n"
     ]
    },
    {
     "ename": "StdinNotImplementedError",
     "evalue": "raw_input was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/123384920.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mjob_ad_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_multiline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JOB AD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mbase_cv_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_multiline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CURRENT CV\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13/123384920.py\u001b[0m in \u001b[0;36mread_multiline\u001b[0;34m(prompt_label)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"END\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \"\"\"\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_stdin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m             raise StdinNotImplementedError(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m: raw_input was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "# ==== 1. Collect user inputs interactively ====\n",
    "\n",
    "print(\"ðŸ§¾ Job Application Assistant\")\n",
    "print(\"I'll help you with ATS analysis, CV tailoring, cover letter, interview prep, and similar jobs.\\n\")\n",
    "\n",
    "# In a notebook, easiest is to paste the text into multi-line string cells,\n",
    "# but if you want to input via console, use this pattern with 'END' markers.\n",
    "\n",
    "def read_multiline(prompt_label):\n",
    "    print(f\"\\nPaste your {prompt_label} below. Type a single line 'END' when you are done:\\n\")\n",
    "    lines = []\n",
    "    while True:\n",
    "        line = input()\n",
    "        if line.strip() == \"END\":\n",
    "            break\n",
    "        lines.append(line)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "job_ad_text = read_multiline(\"JOB AD\")\n",
    "base_cv_text = read_multiline(\"CURRENT CV\")\n",
    "\n",
    "print(\"\\nWhat would you like me to generate?\")\n",
    "print(\"Options: cv, cover_letter, interview guide, jobs, all\")\n",
    "tasks_input = input(\"Enter one or more, separated by commas (e.g. cv, cover_letter, interview, jobs): \")\n",
    "\n",
    "# Normalize tasks\n",
    "selected_tasks = {t.strip().lower() for t in tasks_input.split(\",\") if t.strip()}\n",
    "if \"all\" in selected_tasks:\n",
    "    selected_tasks = {\"cv\", \"cover_letter\", \"interview\", \"jobs\"}\n",
    "\n",
    "print(f\"\\nYou selected: {', '.join(sorted(selected_tasks)) or 'nothing (default: ATS only)'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf29b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T04:36:54.879175Z",
     "iopub.status.busy": "2025-11-24T04:36:54.878556Z",
     "iopub.status.idle": "2025-11-24T04:37:08.324964Z",
     "shell.execute_reply": "2025-11-24T04:37:08.324207Z",
     "shell.execute_reply.started": "2025-11-24T04:36:54.879151Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==== 2. Run selected agents and print outputs ====\n",
    "\n",
    "context_prompt = f\"\"\"\n",
    "========= JOB DESCRIPTION =========\n",
    "{job_ad_text}\n",
    "\n",
    "========= CURRENT CV =========\n",
    "{base_cv_text}\n",
    "\"\"\"\n",
    "\n",
    "# Always do ATS / keywords (cheap + useful)\n",
    "keywords_state = await run_agent(job_analyst_agent, context_prompt)\n",
    "keywords_text = keywords_state.get(\"keywords\", \"No keywords / ATS analysis found.\")\n",
    "\n",
    "revised_cv_text = None\n",
    "cover_letter_text = None\n",
    "interview_guide_text = None\n",
    "similar_jobs_text = None\n",
    "\n",
    "# CV rewrite\n",
    "if \"cv\" in selected_tasks:\n",
    "    cv_prompt = f\"\"\"\n",
    "You will receive a job description and a current CV.\n",
    "\n",
    "Your task:\n",
    "- Rewrite the CV so it is clearly tailored to this role.\n",
    "- Use the job description to emphasise relevant skills and experience.\n",
    "- Use metrics where possible.\n",
    "- Keep the format clean and ATS-friendly.\n",
    "\n",
    "Return ONLY the revised CV.\n",
    "\n",
    "{context_prompt}\n",
    "\"\"\"\n",
    "    cv_state = await run_agent(cvwriter_agent, cv_prompt)\n",
    "    revised_cv_text = cv_state.get(\"revisedcv\", \"No revised CV found.\")\n",
    "\n",
    "# Cover letter\n",
    "if \"cover_letter\" in selected_tasks:\n",
    "    cl_prompt = f\"\"\"\n",
    "You will receive a job description and a current CV.\n",
    "\n",
    "Your task:\n",
    "- Write a professional cover letter for this specific role and candidate.\n",
    "- Use a clear business letter format.\n",
    "- Base the content on the job description and the candidate's profile.\n",
    "\n",
    "Return ONLY the final cover letter.\n",
    "\n",
    "{context_prompt}\n",
    "\"\"\"\n",
    "    cl_state = await run_agent(clwriter_agent, cl_prompt)\n",
    "    cover_letter_text = cl_state.get(\"coverletter\", \"No cover letter found.\")\n",
    "\n",
    "# Interview prep guide\n",
    "if \"interview\" in selected_tasks:\n",
    "    coach_prompt = f\"\"\"\n",
    "You will receive a job description and a current CV.\n",
    "\n",
    "Your task:\n",
    "- Generate an interview preparation guide for this role and candidate:\n",
    "  - 5â€“7 Behavioural / Fit questions + sample answers\n",
    "  - 5â€“7 Technical / Analytics questions + sample answers\n",
    "  - 5 smart questions the candidate should ask the employer\n",
    "\n",
    "Return ONLY the interview preparation guide in markdown.\n",
    "\n",
    "{context_prompt}\n",
    "\"\"\"\n",
    "    coach_state = await run_agent(coach_agent, coach_prompt)\n",
    "    interview_guide_text = coach_state.get(\"interview_guide\", \"No interview guide found.\")\n",
    "\n",
    "# Similar jobs\n",
    "if \"jobs\" in selected_tasks:\n",
    "    jobs_prompt = f\"\"\"\n",
    "Here is a job description for a Data & Insights Analyst â€“ Customer Experience role:\n",
    "\n",
    "{job_ad_text}\n",
    "\n",
    "Use google_search to find 3 similar jobs:\n",
    "- Similar title (Data & Insights Analyst, CX Analyst, Customer Insights Analyst, etc.)\n",
    "- Located in Toronto, ON or Remote (Canada)\n",
    "Return ONLY a markdown bullet list:\n",
    "- Job Title â€“ Company (Location) â€” URL\n",
    "\"\"\"\n",
    "    jobs_state = await run_agent(research_agent, jobs_prompt)\n",
    "    similar_jobs_text = jobs_state.get(\"similar_jobs\", \"No similar jobs found.\")\n",
    "\n",
    "# ==== 3. Print everything nicely ====\n",
    "\n",
    "print(\"\\n===== ATS / KEYWORDS =====\\n\")\n",
    "print(keywords_text)\n",
    "\n",
    "if \"cv\" in selected_tasks:\n",
    "    print(\"\\n===== REVISED CV =====\\n\")\n",
    "    print(revised_cv_text)\n",
    "\n",
    "if \"cover_letter\" in selected_tasks:\n",
    "    print(\"\\n===== COVER LETTER =====\\n\")\n",
    "    print(cover_letter_text)\n",
    "\n",
    "if \"interview\" in selected_tasks:\n",
    "    print(\"\\n===== INTERVIEW PREP (COACH AGENT) =====\\n\")\n",
    "    print(interview_guide_text)\n",
    "\n",
    "if \"jobs\" in selected_tasks:\n",
    "    print(\"\\n===== SIMILAR JOBS (GOOGLE SEARCH) =====\\n\")\n",
    "    print(similar_jobs_text)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 87.11035,
   "end_time": "2025-11-24T04:39:14.339657",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-24T04:37:47.229307",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
